{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "471c2a6d",
   "metadata": {},
   "source": [
    "# Segmentation de tumeurs c√©r√©brales sur IRM avec U-Net  \n",
    "\n",
    "### **Date** : Janvier 2026  \n",
    "### **Objectif** : Construire, entra√Æner et √©valuer un mod√®le U-Net pour la segmentation de tumeurs sur images IRM c√©r√©brales  \n",
    "### **Niveau de complexit√©** : Interm√©diaire ‚Üí Avanc√© (compr√©hension de la segmentation m√©dicale)\n",
    "### **R√©allis√© par** :\n",
    "####      Benzekri Inssaf\n",
    "####      Nathan Kabassele \n",
    "####     Ahmed Jabri\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055b770c",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Importation des biblioth√®ques\n",
    "\n",
    "Cette cellule importe toutes les biblioth√®ques n√©cessaires au projet :\n",
    "\n",
    "- **TensorFlow / Keras** : construction et entra√Ænement du mod√®le Deep Learning  \n",
    "- **NumPy** : manipulation des tableaux num√©riques  \n",
    "- **Matplotlib** : visualisation des images et des courbes  \n",
    "- **OpenCV (cv2)** : sauvegarde et traitement d‚Äôimages  \n",
    "- **Scikit-learn** : s√©paration des donn√©es (train / validation / test)  \n",
    "\n",
    "On affiche √©galement la version de TensorFlow pour assurer la compatibilit√©.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbf12e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# 1. IMPORTATIONS\n",
    "# =============================================\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import zipfile\n",
    "import gdown\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"‚úÖ Importations termin√©es\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5df0f4b",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Pr√©paration du dataset (donn√©es synth√©tiques)\n",
    "\n",
    "Dans un contexte p√©dagogique, nous g√©n√©rons un **dataset synth√©tique** simulant des images IRM c√©r√©brales :\n",
    "\n",
    "### üîπ Pourquoi des donn√©es synth√©tiques ?\n",
    "- √âviter la d√©pendance √† Kaggle / Internet\n",
    "- Faciliter les tests rapides\n",
    "- Comprendre le pipeline sans complexit√© m√©dicale\n",
    "\n",
    "### üîπ Description\n",
    "- Images en niveaux de gris (128√ó128)\n",
    "- Ajout de tumeurs artificielles sous forme de cercles\n",
    "- Cr√©ation des masques de segmentation correspondants\n",
    "- Ajout de bruit r√©aliste\n",
    "\n",
    "Chaque image est sauvegard√©e pour permettre une inspection visuelle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c7c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüì• T√©l√©chargement du dataset depuis Kaggle...\")\n",
    "\n",
    "# Dataset: Brain MRI Segmentation (petit dataset pour test)\n",
    "dataset_url = \"https://www.kaggle.com/datasets/mateuszbuda/lgg-mri-segmentation\"\n",
    "# Alternative: T√©l√©charger directement depuis Google Drive\n",
    "drive_url = \"https://drive.google.com/uc?id=1c0Lx4XSD8XNy1bOe3sS0MfywxHuh-cDr\"\n",
    "\n",
    "dataset_path = \"brain_mri_dataset.zip\"\n",
    "extract_path = \"brain_mri_data\"\n",
    "\n",
    "# Cr√©er un dataset synth√©tique si le t√©l√©chargement √©choue\n",
    "print(\"‚ö†Ô∏è  Cr√©ation de donn√©es synth√©tiques pour la d√©monstration...\")\n",
    "\n",
    "# Cr√©er des dossiers pour les donn√©es synth√©tiques\n",
    "os.makedirs(\"synthetic_data/images\", exist_ok=True)\n",
    "os.makedirs(\"synthetic_data/masks\", exist_ok=True)\n",
    "\n",
    "# G√©n√©rer 100 images synth√©tiques (IRM) et masques\n",
    "num_samples = 100\n",
    "img_size = 128\n",
    "\n",
    "X_synthetic = []\n",
    "y_synthetic = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Image IRM synth√©tique (niveaux de gris avec structures)\n",
    "    img = np.random.randn(img_size, img_size) * 0.1 + 0.5\n",
    "\n",
    "    # Ajouter des \"tumeurs\" synth√©tiques (cercles al√©atoires)\n",
    "    mask = np.zeros((img_size, img_size))\n",
    "\n",
    "    # Nombre al√©atoire de tumeurs (0-3)\n",
    "    num_tumors = np.random.randint(0, 4)\n",
    "    for _ in range(num_tumors):\n",
    "        center_x = np.random.randint(20, img_size-20)\n",
    "        center_y = np.random.randint(20, img_size-20)\n",
    "        radius = np.random.randint(5, 15)\n",
    "\n",
    "        # Cr√©er un cercle pour la tumeur\n",
    "        y, x = np.ogrid[-center_y:img_size-center_y, -center_x:img_size-center_x]\n",
    "        tumor_mask = x*x + y*y <= radius*radius\n",
    "        mask[tumor_mask] = 1\n",
    "\n",
    "        # Ajouter un effet sur l'image IRM\n",
    "        img[tumor_mask] = img[tumor_mask] * 0.7  # Plus sombre\n",
    "\n",
    "    # Ajouter du bruit\n",
    "    img = img + np.random.normal(0, 0.05, (img_size, img_size))\n",
    "    img = np.clip(img, 0, 1)\n",
    "\n",
    "    # Ajouter les canaux\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "\n",
    "    X_synthetic.append(img)\n",
    "    y_synthetic.append(mask)\n",
    "\n",
    "    # Sauvegarder pour visualisation\n",
    "    cv2.imwrite(f\"synthetic_data/images/mri_{i:03d}.png\", (img[:,:,0]*255).astype(np.uint8))\n",
    "    cv2.imwrite(f\"synthetic_data/masks/mask_{i:03d}.png\", (mask[:,:,0]*255).astype(np.uint8))\n",
    "\n",
    "X = np.array(X_synthetic, dtype=np.float32)\n",
    "y = np.array(y_synthetic, dtype=np.float32)\n",
    "\n",
    "print(f\"‚úÖ Dataset synth√©tique cr√©√©: {len(X)} images\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"Pourcentage moyen de tumeurs: {np.mean(y)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcb7b34",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Visualisation des donn√©es\n",
    "\n",
    "Cette cellule permet d‚Äôexplorer visuellement le dataset :\n",
    "\n",
    "Pour chaque √©chantillon affich√© :\n",
    "- üß† Image IRM originale\n",
    "- üéØ Masque de v√©rit√© terrain (ground truth)\n",
    "- üß© Superposition image + masque\n",
    "- üìä Histogramme des intensit√©s de pixels\n",
    "\n",
    "Objectif :\n",
    "> V√©rifier la coh√©rence des donn√©es avant l‚Äôentra√Ænement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed7b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüëÅÔ∏è Visualisation de quelques √©chantillons...\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "\n",
    "for i in range(3):\n",
    "    idx = np.random.randint(0, len(X))\n",
    "\n",
    "    # Image IRM\n",
    "    axes[i, 0].imshow(X[idx, :, :, 0], cmap='gray')\n",
    "    axes[i, 0].set_title(f'IRM {idx}')\n",
    "    axes[i, 0].axis('off')\n",
    "\n",
    "    # Masque de v√©rit√©\n",
    "    axes[i, 1].imshow(y[idx, :, :, 0], cmap='gray')\n",
    "    axes[i, 1].set_title(f'Masque {idx}')\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "    # Superposition\n",
    "    overlay = X[idx, :, :, 0].copy()\n",
    "    overlay = np.stack([overlay]*3, axis=-1)\n",
    "    overlay[y[idx, :, :, 0] > 0.5, 1] = 1  # Vert pour les tumeurs\n",
    "\n",
    "    axes[i, 2].imshow(overlay)\n",
    "    axes[i, 2].set_title(f'Superposition {idx}')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "    # Histogramme des valeurs\n",
    "    axes[i, 3].hist(X[idx].flatten(), bins=50, alpha=0.7)\n",
    "    axes[i, 3].set_title(f'Histogramme {idx}')\n",
    "    axes[i, 3].set_xlabel('Intensit√©')\n",
    "    axes[i, 3].set_ylabel('Fr√©quence')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cc4526",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Division du dataset\n",
    "\n",
    "Les donn√©es sont divis√©es comme suit :\n",
    "- **70 %** entra√Ænement\n",
    "- **15 %** validation\n",
    "- **15 %** test\n",
    "\n",
    "Pourquoi cette s√©paration ?\n",
    "- Le mod√®le apprend sur le train set\n",
    "- Les hyperparam√®tres sont ajust√©s via le validation set\n",
    "- Les performances finales sont mesur√©es sur le test set\n",
    "\n",
    "On affiche √©galement le **pourcentage moyen de tumeurs** dans chaque sous-ensemble.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaaed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä Division des donn√©es...\")\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Train set: {len(X_train)} images\")\n",
    "print(f\"Validation set: {len(X_val)} images\")\n",
    "print(f\"Test set: {len(X_test)} images\")\n",
    "print(f\"Pourcentage tumeurs (train): {np.mean(y_train)*100:.2f}%\")\n",
    "print(f\"Pourcentage tumeurs (val): {np.mean(y_val)*100:.2f}%\")\n",
    "print(f\"Pourcentage tumeurs (test): {np.mean(y_test)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb9271",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Construction du mod√®le U-Net\n",
    "\n",
    "Le mod√®le utilis√© est un **U-Net**, architecture tr√®s populaire en segmentation m√©dicale.\n",
    "\n",
    "### üîπ Architecture\n",
    "- **Encoder** : extraction progressive de caract√©ristiques\n",
    "- **Bottleneck** : repr√©sentation compacte\n",
    "- **Decoder** : reconstruction spatiale\n",
    "- **Skip connections** : pr√©servation des d√©tails fins\n",
    "\n",
    "### üîπ Fonctions personnalis√©es\n",
    "- **Dice coefficient** : mesure de similarit√© entre masques\n",
    "- **IoU (Intersection over Union)** : m√©trique cl√© en segmentation\n",
    "\n",
    "### üîπ Compilation\n",
    "- Optimiseur : Adam\n",
    "- Fonction de perte : Binary Crossentropy\n",
    "- M√©triques : Accuracy, IoU, Dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93010ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nü§ñ Construction du mod√®le U-Net...\")\n",
    "\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# D√©finition des m√©triques\n",
    "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "\n",
    "def iou_metric(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) - intersection\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "# Construction du mod√®le\n",
    "inputs = layers.Input(shape=(128, 128, 1))\n",
    "\n",
    "# Encoder\n",
    "c1 = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
    "c1 = layers.Conv2D(32, 3, activation='relu', padding='same')(c1)\n",
    "p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "c2 = layers.Conv2D(64, 3, activation='relu', padding='same')(p1)\n",
    "c2 = layers.Conv2D(64, 3, activation='relu', padding='same')(c2)\n",
    "p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "c3 = layers.Conv2D(128, 3, activation='relu', padding='same')(p2)\n",
    "c3 = layers.Conv2D(128, 3, activation='relu', padding='same')(c3)\n",
    "p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "# Centre\n",
    "c4 = layers.Conv2D(256, 3, activation='relu', padding='same')(p3)\n",
    "c4 = layers.Conv2D(256, 3, activation='relu', padding='same')(c4)\n",
    "\n",
    "# Decoder\n",
    "u5 = layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(c4)\n",
    "u5 = layers.concatenate([u5, c3])\n",
    "c5 = layers.Conv2D(128, 3, activation='relu', padding='same')(u5)\n",
    "c5 = layers.Conv2D(128, 3, activation='relu', padding='same')(c5)\n",
    "\n",
    "u6 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(c5)\n",
    "u6 = layers.concatenate([u6, c2])\n",
    "c6 = layers.Conv2D(64, 3, activation='relu', padding='same')(u6)\n",
    "c6 = layers.Conv2D(64, 3, activation='relu', padding='same')(c6)\n",
    "\n",
    "u7 = layers.Conv2DTranspose(32, 2, strides=(2, 2), padding='same')(c6)\n",
    "u7 = layers.concatenate([u7, c1])\n",
    "c7 = layers.Conv2D(32, 3, activation='relu', padding='same')(u7)\n",
    "c7 = layers.Conv2D(32, 3, activation='relu', padding='same')(c7)\n",
    "\n",
    "outputs = layers.Conv2D(1, 1, activation='sigmoid')(c7)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compilation\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', iou_metric, dice_coef]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d68ad13",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Entra√Ænement du mod√®le\n",
    "\n",
    "Le mod√®le est entra√Æn√© sur les donn√©es d‚Äôapprentissage avec :\n",
    "\n",
    "### üîπ Callbacks utilis√©s\n",
    "- **EarlyStopping** : √©vite le sur-apprentissage\n",
    "- **ReduceLROnPlateau** : ajuste automatiquement le learning rate\n",
    "\n",
    "### üîπ Param√®tres\n",
    "- Epochs : 20\n",
    "- Batch size : 8\n",
    "\n",
    "√Ä la fin de l‚Äôentra√Ænement, le mod√®le est sauvegard√© au format `.keras`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3655d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüöÄ D√©but de l'entra√Ænement...\")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3\n",
    "    )\n",
    "]\n",
    "\n",
    "# Entra√Ænement\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=8,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Sauvegarde\n",
    "model.save('brain_tumor_model.keras')\n",
    "print(\"‚úÖ Mod√®le sauvegard√©: brain_tumor_model.keras\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a55f8b",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Visualisation de l‚Äôapprentissage\n",
    "\n",
    "Cette cellule affiche les courbes suivantes :\n",
    "- üìâ Loss (train / validation)\n",
    "- ‚úÖ Accuracy\n",
    "- üìê IoU\n",
    "- üéØ Dice coefficient\n",
    "\n",
    "Objectif :\n",
    "> V√©rifier la convergence du mod√®le et d√©tecter un √©ventuel overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de81837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìà Visualisation de l'entra√Ænement...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(history.history['loss'], label='Train Loss')\n",
    "axes[0, 0].plot(history.history['val_loss'], label='Val Loss')\n",
    "axes[0, 0].set_title('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 1].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "axes[0, 1].plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "axes[0, 1].set_title('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# IoU\n",
    "axes[1, 0].plot(history.history['iou_metric'], label='Train IoU')\n",
    "axes[1, 0].plot(history.history['val_iou_metric'], label='Val IoU')\n",
    "axes[1, 0].set_title('IoU Metric')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Dice\n",
    "axes[1, 1].plot(history.history['dice_coef'], label='Train Dice')\n",
    "axes[1, 1].plot(history.history['val_dice_coef'], label='Val Dice')\n",
    "axes[1, 1].set_title('Dice Coefficient')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f9cac",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ √âvaluation du mod√®le sur le test set\n",
    "\n",
    "Cette √©tape mesure les performances r√©elles du mod√®le sur des donn√©es jamais vues :\n",
    "\n",
    "### üîπ M√©triques calcul√©es\n",
    "- IoU moyen\n",
    "- Dice moyen\n",
    "- Pr√©cision\n",
    "- Rappel\n",
    "- F1-score\n",
    "\n",
    "Une analyse de **sur-segmentation** ou **sous-segmentation** est √©galement r√©alis√©e.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b8fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä √âvaluation sur le test set...\")\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred = model.predict(X_test, verbose=1)\n",
    "y_pred_binary = (y_pred > 0.5).astype(np.float32)\n",
    "\n",
    "# Calcul des m√©triques\n",
    "iou_scores = []\n",
    "dice_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    iou = iou_metric(y_test[i], y_pred_binary[i]).numpy()\n",
    "    dice = dice_coef(y_test[i], y_pred_binary[i]).numpy()\n",
    "\n",
    "    y_true_f = y_test[i].flatten()\n",
    "    y_pred_f = y_pred_binary[i].flatten()\n",
    "\n",
    "    tp = np.sum((y_true_f == 1) & (y_pred_f == 1))\n",
    "    fp = np.sum((y_true_f == 0) & (y_pred_f == 1))\n",
    "    fn = np.sum((y_true_f == 1) & (y_pred_f == 0))\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-6)\n",
    "    recall = tp / (tp + fn + 1e-6)\n",
    "\n",
    "    iou_scores.append(iou)\n",
    "    dice_scores.append(dice)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìä R√âSULTATS FINAUX\")\n",
    "print(\"=\"*50)\n",
    "print(f\"IoU moyen: {np.mean(iou_scores):.4f} (+/- {np.std(iou_scores):.4f})\")\n",
    "print(f\"Dice moyen: {np.mean(dice_scores):.4f} (+/- {np.std(dice_scores):.4f})\")\n",
    "print(f\"Pr√©cision moyenne: {np.mean(precision_scores):.4f}\")\n",
    "print(f\"Rappel moyen: {np.mean(recall_scores):.4f}\")\n",
    "print(f\"F1-Score: {2 * np.mean(precision_scores) * np.mean(recall_scores) / (np.mean(precision_scores) + np.mean(recall_scores) + 1e-6):.4f}\")\n",
    "\n",
    "# Statistiques\n",
    "avg_tumor_actual = np.mean(y_test) * 100\n",
    "avg_tumor_pred = np.mean(y_pred_binary) * 100\n",
    "print(f\"\\nüìà STATISTIQUES:\")\n",
    "print(f\"  Tumeurs r√©elles moyennes: {avg_tumor_actual:.1f}%\")\n",
    "print(f\"  Tumeurs pr√©dites moyennes: {avg_tumor_pred:.1f}%\")\n",
    "print(f\"  Diff√©rence: {abs(avg_tumor_actual - avg_tumor_pred):.1f}%\")\n",
    "\n",
    "if avg_tumor_pred > avg_tumor_actual:\n",
    "    print(f\"  ‚ö†Ô∏è  SUR-SEGMENTATION: {avg_tumor_pred - avg_tumor_actual:.1f}% de faux positifs\")\n",
    "elif avg_tumor_pred < avg_tumor_actual:\n",
    "    print(f\"  ‚ö†Ô∏è  UNDER-SEGMENTATION: {avg_tumor_actual - avg_tumor_pred:.1f}% de faux n√©gatifs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b7b58f",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Visualisation des pr√©dictions\n",
    "\n",
    "Pour plusieurs images al√©atoires du test set :\n",
    "- Image IRM originale\n",
    "- Masque r√©el\n",
    "- Masque pr√©dit\n",
    "- Superposition couleur :\n",
    "  - üü¢ Vert : v√©rit√© terrain\n",
    "  - üî¥ Rouge : pr√©diction\n",
    "  - üü° Jaune : pr√©diction correcte\n",
    "\n",
    "Chaque image affiche √©galement son score IoU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7cf412",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüëÅÔ∏è Visualisation des pr√©dictions...\")\n",
    "\n",
    "# S√©lectionner 3 exemples al√©atoires\n",
    "indices = np.random.choice(len(X_test), 3, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(15, 10))\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    # Image originale\n",
    "    img = X_test[idx, :, :, 0]\n",
    "\n",
    "    # V√©rit√© terrain\n",
    "    true_mask = y_test[idx, :, :, 0]\n",
    "\n",
    "    # Pr√©diction\n",
    "    pred = y_pred[idx, :, :, 0]\n",
    "    pred_binary = (pred > 0.5).astype(np.float32)\n",
    "\n",
    "    # Calcul IoU\n",
    "    iou = iou_metric(true_mask, pred_binary).numpy()\n",
    "\n",
    "    # Image IRM\n",
    "    axes[i, 0].imshow(img, cmap='gray')\n",
    "    axes[i, 0].set_title(f'IRM {idx}')\n",
    "    axes[i, 0].axis('off')\n",
    "\n",
    "    # V√©rit√© terrain\n",
    "    axes[i, 1].imshow(true_mask, cmap='gray')\n",
    "    axes[i, 1].set_title(f'V√©rit√© {idx}')\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "    # Pr√©diction binaire\n",
    "    axes[i, 2].imshow(pred_binary, cmap='gray')\n",
    "    axes[i, 2].set_title(f'Pr√©diction\\nIoU: {iou:.3f}')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "    # Superposition\n",
    "    overlay = np.stack([img]*3, axis=-1)\n",
    "    overlay[true_mask > 0.5, 1] = 1  # Vert pour v√©rit√©\n",
    "    overlay[pred_binary > 0.5, 0] = 1  # Rouge pour pr√©diction\n",
    "    overlay[(true_mask > 0.5) & (pred_binary > 0.5), 0] = 1  # Jaune pour correct\n",
    "    overlay[(true_mask > 0.5) & (pred_binary > 0.5), 1] = 1\n",
    "\n",
    "    axes[i, 3].imshow(overlay)\n",
    "    axes[i, 3].set_title('Superposition\\n(Vert=Vrai, Rouge=Pr√©dit)')\n",
    "    axes[i, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeb9f1b",
   "metadata": {},
   "source": [
    "## üîü Analyse d√©taill√©e d‚Äôun cas test\n",
    "\n",
    "Cette cellule analyse un exemple pr√©cis du test set :\n",
    "\n",
    "- Comparaison pixel par pixel\n",
    "- Carte de confiance (probabilit√©s)\n",
    "- Carte d‚Äôerreur\n",
    "- Calcul pr√©cis des m√©triques\n",
    "\n",
    "Objectif :\n",
    "> Comprendre **o√π et pourquoi** le mod√®le se trompe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14fe5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîç Test d√©taill√© sur un exemple...\")\n",
    "\n",
    "test_idx = 0  # Premier exemple du test set\n",
    "test_img = X_test[test_idx]\n",
    "true_mask = y_test[test_idx]\n",
    "\n",
    "# Pr√©diction\n",
    "pred = model.predict(test_img[np.newaxis, ...], verbose=0)[0]\n",
    "pred_binary = (pred > 0.5).astype(np.float32)\n",
    "\n",
    "# M√©triques\n",
    "iou = iou_metric(true_mask, pred_binary).numpy()\n",
    "dice = dice_coef(true_mask, pred_binary).numpy()\n",
    "\n",
    "print(f\"\\nüìä M√©triques pour l'exemple {test_idx}:\")\n",
    "print(f\"IoU: {iou:.4f}\")\n",
    "print(f\"Dice: {dice:.4f}\")\n",
    "print(f\"Tumeurs r√©elles: {np.mean(true_mask)*100:.1f}%\")\n",
    "print(f\"Tumeurs pr√©dites: {np.mean(pred_binary)*100:.1f}%\")\n",
    "\n",
    "# Visualisation d√©taill√©e\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "# Image IRM\n",
    "axes[0, 0].imshow(test_img[:, :, 0], cmap='gray')\n",
    "axes[0, 0].set_title('IRM Originale')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# V√©rit√© terrain\n",
    "axes[0, 1].imshow(true_mask[:, :, 0], cmap='gray')\n",
    "axes[0, 1].set_title('V√©rit√© Terrain')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Pr√©diction\n",
    "axes[0, 2].imshow(pred_binary[:, :, 0], cmap='gray')\n",
    "axes[0, 2].set_title(f'Pr√©diction (IoU: {iou:.3f})')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Diff√©rence\n",
    "diff = np.abs(true_mask[:, :, 0] - pred_binary[:, :, 0])\n",
    "axes[1, 0].imshow(diff, cmap='hot')\n",
    "axes[1, 0].set_title('Diff√©rence')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# Carte de confiance\n",
    "axes[1, 1].imshow(pred[:, :, 0], cmap='viridis')\n",
    "axes[1, 1].set_title('Carte de Confiance')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "# Superposition\n",
    "overlay = np.stack([test_img[:, :, 0]]*3, axis=-1)\n",
    "overlay[true_mask[:, :, 0] > 0.5, 1] = 0.7\n",
    "overlay[pred_binary[:, :, 0] > 0.5, 0] = 0.7\n",
    "axes[1, 2].imshow(overlay)\n",
    "axes[1, 2].set_title('Superposition')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.suptitle(f'Analyse D√©taill√©e - Exemple {test_idx}', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d57336",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Analyse des erreurs du mod√®le\n",
    "\n",
    "Cette derni√®re section :\n",
    "- Identifie la **meilleure** et la **pire** pr√©diction\n",
    "- Affiche la distribution des scores IoU\n",
    "- Fournit un r√©sum√© global des performances\n",
    "\n",
    "Cette analyse est essentielle pour :\n",
    "- am√©liorer le mod√®le,\n",
    "- ajuster le seuil,\n",
    "- ou enrichir les donn√©es.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüî¨ Analyse des erreurs...\")\n",
    "\n",
    "# Trouver les meilleurs et pires pr√©dictions\n",
    "all_ious = [iou_metric(y_test[i], (model.predict(X_test[i:i+1]) > 0.5).astype(np.float32)).numpy()\n",
    "            for i in range(len(X_test))]\n",
    "\n",
    "best_idx = np.argmax(all_ious)\n",
    "worst_idx = np.argmin(all_ious)\n",
    "\n",
    "print(f\"\\nüéØ Meilleure pr√©diction: index {best_idx}, IoU = {all_ious[best_idx]:.4f}\")\n",
    "print(f\"‚ö†Ô∏è  Pire pr√©diction: index {worst_idx}, IoU = {all_ious[worst_idx]:.4f}\")\n",
    "\n",
    "# Histogramme des IoU\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(all_ious, bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(x=np.mean(all_ious), color='red', linestyle='--', label=f'Moyenne: {np.mean(all_ious):.3f}')\n",
    "plt.xlabel('IoU Score')\n",
    "plt.ylabel('Fr√©quence')\n",
    "plt.title('Distribution des Scores IoU sur le Test Set')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"‚úÖ NOTEBOOK TERMIN√â AVEC SUCC√àS!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"üìä R√©sum√© des performances:\")\n",
    "print(f\"   - IoU moyen: {np.mean(all_ious):.3f}\")\n",
    "print(f\"   - Meilleur IoU: {np.max(all_ious):.3f}\")\n",
    "print(f\"   - Pire IoU: {np.min(all_ious):.3f}\")\n",
    "print(f\"   - Mod√®le sauvegard√©: brain_tumor_model.keras\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
